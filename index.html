
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title> Hand-Object Contact Consistency Reasoning for Human Grasps Generation </title>
    
    <link href="style.css" rel="stylesheet">

    <style>
      body {
        font-family: Arial;
        font-size:15px;
        margin: 60px auto;
        width: auto;
        max-width: 1200px;
      }



      hr {
        border: 0;
        height: 1.0px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3));
      }

      .gap-30 {
      width:100%;
      height:30px;
      }

      .gap-20 {
      width:100%;
      height:20px;
      }

      .gap-10 {
      width:100%;
      height:10px;
      }

      .gap-5 {
      width:100%;
      height:5px;
      }

      .no-gutters {
      margin-right: 0;
      margin-left: 0;

      > .col,
      > [class*="col-"] {
        padding-right: 0;
        padding-left: 0;
      }
    }

    </style>

  </head>

  <div class="container">

    <center><span style="font-size:36px"> Hand-Object Contact Consistency Reasoning for Human Grasps Generation </span></center>
    <div class="gap-5"></div>

    <!--------------------- Author Names --------------------->
    <div class="row">
      <div class="col-md-2">
      </div>

      <div class="col-md-2">
        <center><span style="font-size:16px">
          <a href="https://hwjiang1510.github.io/">Hanwen Jiang*</a>
        </span></center>
      </div>

      <div class="col-md-2">
        <center><span style="font-size:16px">
          <a href="https://stevenlsw.github.io/">Shaowei Liu*</a>
        </span></center>
      </div>
      
      <div class="col-md-2">
        <center><span style="font-size:16px">
          <a href="https://github.com/jiashunwang">Jiashun Wang</a>
        </span></center>
      </div>
      
      <div class="col-md-2">
        <center><span style="font-size:16px">
          <a href="https://xiaolonw.github.io/">Xiaolong Wang</a>
        </span></center>
      </div>

      <div class="col-md-2">
      </div>
    </div>

    <!--------------------- AFFILIATIONS --------------------->
    <div class="gap-5"></div>
    <div class="row">
      <div class="col-md-5">
      </div>
      
      <div class="col-md-2">
        <center><span style="font-size:16px">
          UC San Diego
        </span></center>
      </div>

      <div class="col-md-5">
      </div>
    </div>
    <!--------------------- paper and code link --------------------->
    <div class="gap-5"></div>
    <div class="row">
      <div class="col-md-4">
      </div>

      <div class="col-md-2">
        <center><span style="font-size:16px">
          [paper (coming soon)]<!---------------------<a href="https://arxiv.org/pdf/2012.05522.pdf">[arXiv]</a>--------------------->
        </span></center>
      </div>

      <div class="col-md-2">
        <center><span style="font-size:16px">
          [code (coming soon)]
        </span></center>
      </div>

      <div class="col-md-4">
      </div>
    </div>
    <!--------------------- teaser --------------------->
    <div class="gap-5"></div>
    <div class="img" style="text-align:center">
      <img src="./sources/teaser.gif" style="margin:0.2em;max-width:75%">
    </div>

    <!--------------------- abstract --------------------->
    <div class="gap-20"></div>
    <b><span style="font-size:20px">Abstract:</span></b><br>
    <div class="gap-5"></div>

    <p>  While predicting robot grasps with parallel jaw grippers have been well studied and widely applied in robot manipulation tasks, the study on natural human grasp generation with a multi-finger hand remains a very challenging problem. In this paper, we propose to generate human grasps given a 3D object in the world. Our key observation is that it is crucial to model the consistency between the hand contact points and object contact regions. That is, we encourage the prior hand contact points to be close to the object surface and the object common contact regions to be touched by the hand at the same time. Based on the hand-object contact consistency, we design novel objectives in training the human grasp generation model and also a new self-supervised task which allows the grasp generation network to be adjusted even during test time. Our experiments show significant improvement in human grasp generation over state-of-the-art approaches by a large margin. More interestingly, by optimizing the model during test time with the self-supervised task, it helps achieve larger gain on unseen and out-of-domain objects.   <hr>
<!--
    <b><span style="font-size:20px">Methods:</span></b><br>

    <div class="gap-20"></div>
    <div class="img" style="text-align:center">
      <img src="./figs/methodv2.png" style="margin:0.2em;max-width:75%">
    </div>
    <div class="gap-20"></div>
    Our model takes N video frames as inputs and predicts the object locations for the future T timesteps, as illustrated above. We first extract the image feature representation using a ConvNet for each frame, and then apply RoI pooling to obtain object-centric visual features. These object feature representations are forwarded to the interaction modules to perform interaction reasoning and predict future object locations.
The whole pipeline is trained end-to-end by minimizing the loss between predicted and the ground-truth object locations. Since the parameters of each interaction module is shared so we can apply this process recurrently over time to an arbitrary T during testing.
--> 
    
<!--
    <div class="gap-20"></div>
    <b><span style="font-size:20px">Video:</span></b><br>
    <div class="gap-5"></div>

    <div class="gap-20"></div>
    <div class="embed-responsive embed-responsive-16by9">
    <iframe width="716" height="403" src="https://www.youtube.com/embed/iDrjIGrJz2Q" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
    </div>
    <hr>
--> 
    
    <b><span style="font-size:20px">Methods:</span></b><br>

    <div class="gap-20"></div>
    <div class="img" style="text-align:center">
      <img src="./sources/affordance-main.png" style="margin:0.2em;max-width:90%">
    </div>
    <div class="gap-20"></div>
    We propose two networks: (1). A GraspCVAE for human grasp generation; (2). A ContactNet for predicting object contact maps. During training, the two networks are trained on ground truth data separately. During testing, the two networks are unified in a cascade manner for performing Test-time Adaptation (TTA). A initial grasp is predicted by the GraspCVAE decoder, and it is inputted together with the object into ContactNet for predicting a target contact map. We then leverage the contact consistency between outputs of the two networks for adjusting the initial grasp, where the target contact map serves as a self-supervision signal.
    <hr>
    


    <div class="gap-10"></div>
    <b><span style="font-size:20px">Qualitative Results:</span></b><br>
    <div class="gap-20"></div>
    
    <center><b><span style="font-size:20px"> Input and output </span></b></center>
    <div class="gap-10"></div>
    <center><p><span style="font-size:14px"> At test-time, the input of the grasp generation framework is only the object. 
      The models predict hand meshes for grasping the objects. 
      We also show the contact between hand-object, where brighter regions have more contactness. </span></p></center>
    <div class="gap-10"></div>
    <div class="gap-10"></div>
    <div class="row no-gutters">
      <div class="col-12">
        <img src="./sources/input_output.jpg" style="margin:1em;max-width:80%">
      </div>
    </div>
    <hr>

    <center><b><span style="font-size:20px"> Obamn (in-domain objects) </span></b></center>
    <div class="gap-10"></div>


    <center><b><span style="font-size:18px"> Compare with GT </span></b></center>
    <center><p><span style="font-size:14px"> (Note that grasp generation is multi-modal, and generated grasps can be different from GT. Ideal grasps should be natural and physically plausible.) </span></p></center>
    <div class="gap-5"></div>

    <div class="row no-gutters">
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <center> GT </center>
          </div>
          <div class="col-3">
            <center> Ours </center>
          </div>
        </div>
      </div>
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <center> GT </center>
          </div>
          <div class="col-3">
            <center> Ours </center>
          </div>
        </div>
      </div>
    </div>

    <div class="row no-gutters">
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <img src="./sources/obman_gt_0.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
          <div class="col-3">
            <img src="./sources/obman_pred_0.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
        </div>
      </div>
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <img src="./sources/obman_gt_1.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
          <div class="col-3">
            <img src="./sources/obman_pred_1.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
        </div>
      </div>
    </div>

    <div class="row no-gutters">
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <img src="./sources/obman_gt_2.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
          <div class="col-3">
            <img src="./sources/obman_pred_2.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
        </div>
      </div>
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <img src="./sources/obman_gt_3.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
          <div class="col-3">
            <img src="./sources/obman_pred_3.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
        </div>
      </div>
    </div>
    <hr>

    <div class="gap-10"></div>
    <center><b><span style="font-size:18px"> More results </span></b></center>
    <center><p><span style="font-size:14px"> (Every example is shown with 3 views) </span></p></center>
    <div class="gap-5"></div>
    <div class="row no-gutters">
      <div class="col-12">
        <img src="./sources/supp_obman.png" style="margin:1em;max-width:95%">
      </div>
    </div>
    <hr>


    <div class="gap-10"></div>
    <center><b><span style="font-size:20px"> HO-3D and FPHA (Out-of-domain objects) </span></b></center>
    <div class="gap-10"></div>

    <center><b><span style="font-size:18px"> Results in 3D </span></b></center>
    <div class="gap-10"></div>

    <div class="row no-gutters">
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <center> Example 1 </center>
          </div>
          <div class="col-3">
            <center> Example 2 </center>
          </div>
        </div>
      </div>
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <center> Example 3 </center>
          </div>
          <div class="col-3">
            <center> Example 4 </center>
          </div>
        </div>
      </div>
    </div>

    <div class="row no-gutters">
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <img src="./sources/obman_ho_0.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
          <div class="col-3">
            <img src="./sources/obman_ho_1.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
        </div>
      </div>
      <div class="col-6">
        <div class="row no-gutters">
          <div class="col-3">
            <img src="./sources/obman_ho_2.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
          <div class="col-3">
            <img src="./sources/obman_ho_3.gif" style="max-width:95%;border:1px solid #021a40;">
          </div>
        </div>
      </div>
    </div>
    <hr>


    <center><b><span style="font-size:18px"> More results </span></b></center>
    <div class="gap-10"></div>
    <div class="row no-gutters">
      <div class="col-12">
        <img src="./sources/supp_generalization.png" style="margin:1em;max-width:95%">
      </div>
    </div>
    <hr>
<!--
    <b><span style="font-size:20px">Qualitative Results:</span></b><br>
    <div class="gap-20"></div>
  
    <div class="embed-responsive embed-responsive-32by9">  
    <video width="800px" playsinline autoplay loop preload muted> <source src="./sources/wp1.mp4" type=video/mp4><video>
    </div>
      
    <div class="embed-responsive embed-responsive-32by9">
    <video width="800px" playsinline autoplay loop preload muted> <source src="./sources/wp2.mp4" type=video/mp4><video>
    </div>
    
    <div class="embed-responsive embed-responsive-32by9">
    <video width="800px" playsinline autoplay loop preload muted> <source src="./sources/wp3.mp4" type=video/mp4><video>
    </div>
      
    <div class="embed-responsive embed-responsive-32by9">
    <video width="800px" playsinline autoplay loop preload muted> <source src="./sources/wp4_.mp4" type=video/mp4><video>
    </div>
      
    <div class="embed-responsive embed-responsive-32by9">
    <video width="800px" playsinline autoplay loop preload muted> <source src="./sources/wp5.mp4" type=video/mp4><video>
    </div>
      
    <div class="embed-responsive embed-responsive-32by9">
    <video width="800px" playsinline autoplay loop preload muted> <source src="./sources/wp6.mp4" type=video/mp4><video>
    </div>
-->

    <!--
    <div class="gap-10"></div>
    <center><b><span style="font-size:18px"> Changing body shape </span></b></center>
    <div class="gap-10"></div>

    <div class="row no-gutters">
      <div class="col-3">
        <img src="./sources/shape_eg1.gif" style="margin:1em;max-width:95%">
      </div>

      <div class="col-3">
        <img src="./sources/shape_eg2.gif" style="margin:1em;max-width:95%">
      </div>

      <div class="col-3">
        <img src="./sources/shape_eg3.gif" style="margin:1em;max-width:95%">
      </div>
    </div>
      
    <div class="gap-10"></div>
    <center><b><span style="font-size:18px"> Changing latent z </span></b></center>
    <div class="gap-10"></div>
    <center>
    <div class="row no-gutters">
      <div class="col-3">
        <img src="./sources/z_eg1.gif" style="margin:1em;max-width:95%">
      </div>

      <div class="col-3">
        <img src="./sources/z_eg2.gif" style="margin:1em;max-width:95%">
      </div>

      <div class="col-3">
        <img src="./sources/z_eg3.gif" style="margin:1em;max-width:95%">
      </div>
    </div>
    </center>
    <hr>
    -->

<!--
    <b><span style="font-size:20px">Paper:</span></b><br>
    <div class="img" style="text-align:center">
      <a href="https://arxiv.org/pdf/2012.05522.pdf">
        <img src="./sources/paper1.png" style="margin:1.2em;max-width:95%">
      </a>
    </div>
-->

<!--
    <hr>
    <b><span style="font-size:20px">Bibtex:</span></b>
    <br>
    <div class="gap-10"></div>
    <pre>
    @misc{wang2020synthesizing,
      title={Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes}, 
      author={Jiashun Wang and Huazhe Xu and Jingwei Xu and Sifei Liu and Xiaolong Wang},
      year={2020},
      eprint={2012.05522},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
    }
    </pre>
-->
    
</html>
